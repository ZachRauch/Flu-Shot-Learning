{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T16:31:54.978424Z",
     "start_time": "2022-04-19T16:31:54.968179Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split,\\\n",
    "    GridSearchCV, cross_val_score\n",
    "from sklearn.dummy import DummyClassifier \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder,\\\n",
    "    FunctionTransformer, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,\\\n",
    "    GradientBoostingClassifier, AdaBoostClassifier,\\\n",
    "    BaggingClassifier, ExtraTreesClassifier,\\\n",
    "    VotingClassifier, StackingClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix, recall_score,\\\n",
    "    accuracy_score, precision_score, f1_score\n",
    "\n",
    "import xgboost\n",
    "\n",
    "import pickle\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImPipeline\n",
    "\n",
    "#https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/\n",
    "from sklearn.metrics import roc_curve\n",
    "from numpy import sqrt, argmax\n",
    "\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T16:31:55.179843Z",
     "start_time": "2022-04-19T16:31:55.175395Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T16:31:55.524542Z",
     "start_time": "2022-04-19T16:31:55.515651Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from '/Users/zachrauch/Documents/Flatiron/Projects/Flu-Shot-Learning/Workspace/model.py'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T16:31:56.280653Z",
     "start_time": "2022-04-19T16:31:56.264616Z"
    }
   },
   "outputs": [],
   "source": [
    "class ModelWithCV():\n",
    "    '''Structure to save the model and more easily see its crossvalidation'''\n",
    "    \n",
    "    def __init__(self, model, model_name, X, y, cv_now=True):\n",
    "        self.model = model\n",
    "        self.name = model_name\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        # For CV results\n",
    "        self.cv_results = None\n",
    "        self.cv_mean = None\n",
    "        self.cv_median = None\n",
    "        self.cv_std = None\n",
    "        #\n",
    "        if cv_now:\n",
    "            self.cross_validate()\n",
    "        \n",
    "    def cross_validate(self, X=None, y=None, kfolds=10):\n",
    "        '''\n",
    "        Perform cross-validation and return results.\n",
    "        \n",
    "        Args: \n",
    "          X:\n",
    "            Optional; Training data to perform CV on. Otherwise use X from object\n",
    "          y:\n",
    "            Optional; Training data to perform CV on. Otherwise use y from object\n",
    "          kfolds:\n",
    "            Optional; Number of folds for CV (default is 10)  \n",
    "        '''\n",
    "        \n",
    "        cv_X = X if X else self.X\n",
    "        cv_y = y if y else self.y\n",
    "\n",
    "        self.cv_results = cross_val_score(self.model, cv_X, cv_y, cv=kfolds)\n",
    "        self.cv_mean = np.mean(self.cv_results)\n",
    "        self.cv_median = np.median(self.cv_results)\n",
    "        self.cv_std = np.std(self.cv_results)\n",
    "\n",
    "        \n",
    "#     def print_cv_summary(self):\n",
    "#         cv_summary = (\n",
    "#         f'''CV Results for `{self.name}` model:\n",
    "#             {self.cv_mean:.5f} ± {self.cv_std:.5f} accuracy\n",
    "#             recall_score: {recall_score(self.y, self.model.predict(self.X))}\n",
    "#             precision_score: {precision_score(self.y, self.model.predict(self.X))}\n",
    "#             f1_score: {f1_score(self.y, self.model.predict(self.X))}    \n",
    "#         ''')\n",
    "#         print(cv_summary)\n",
    "    def print_cv_summary(self):\n",
    "        cv_summary = (\n",
    "        f'''CV Results for `{self.name}` model:\n",
    "            {self.cv_mean:.5f} ± {self.cv_std:.5f} accuracy\n",
    "            recall_score: {cross_val_score(self.model, self.X, self.y, cv=10, scoring='recall').mean()}\n",
    "            precision_score: {cross_val_score(self.model, self.X, self.y, cv=10, scoring='average_precision').mean()}\n",
    "            f1_score: {cross_val_score(self.model, self.X, self.y, cv=10, scoring='f1').mean()}    \n",
    "        ''')\n",
    "        print(cv_summary)\n",
    "        \n",
    "    def plot_cv(self, ax):\n",
    "        '''\n",
    "        Plot the cross-validation values using the array of results and given \n",
    "        Axis for plotting.\n",
    "        '''\n",
    "        ax.set_title(f'CV Results for `{self.name}` Model')\n",
    "        # Thinner violinplot with higher bw\n",
    "        sns.violinplot(y=self.cv_results, ax=ax, bw=.4)\n",
    "        sns.swarmplot(\n",
    "                y=self.cv_results,\n",
    "                color='orange',\n",
    "                size=10,\n",
    "                alpha= 0.8,\n",
    "                ax=ax\n",
    "        )\n",
    "\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T16:02:53.075735Z",
     "start_time": "2022-04-19T16:02:53.069621Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T16:31:58.386825Z",
     "start_time": "2022-04-19T16:31:58.362437Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ModelWithCV at 0x7fde60077880>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('tuned_logreg.sav', 'rb') as f:\n",
    "    tlog = pickle.load(f)\n",
    "tlog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T16:32:07.621131Z",
     "start_time": "2022-04-19T16:31:59.143292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results for `tlog_pipe` model:\n",
      "            0.77751 ± 0.01195 accuracy\n",
      "            recall_score: 0.7461571315057609\n",
      "            precision_score: 0.8288517338281706\n",
      "            f1_score: 0.7587960505203576    \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "tlog.print_cv_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T16:32:10.781858Z",
     "start_time": "2022-04-19T16:32:10.730655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(transformers=[('subpipe_cat',\n",
       "                                                  Pipeline(steps=[('cat_impute',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(drop='first',\n",
       "                                                                                 handle_unknown='ignore',\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  Index(['behavioral_antiviral_meds', 'behavioral_avoidance',\n",
       "       'behavioral_face_mask', 'behavioral_wash_hands',\n",
       "       'behavioral_large_gatherings',...\n",
       "                                                  Pipeline(steps=[('num_impute',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('ss',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['h1n1_concern',\n",
       "                                                   'h1n1_knowledge',\n",
       "                                                   'opinion_h1n1_vacc_effective',\n",
       "                                                   'opinion_h1n1_risk',\n",
       "                                                   'opinion_h1n1_sick_from_vacc',\n",
       "                                                   'opinion_seas_vacc_effective',\n",
       "                                                   'opinion_seas_risk',\n",
       "                                                   'opinion_seas_sick_from_vacc'])])),\n",
       "                ('logreg',\n",
       "                 LogisticRegression(C=0.3, max_iter=5, random_state=42,\n",
       "                                    solver='liblinear'))])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tlog.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tuned_knn.sav', 'rb') as f:\n",
    "    tknn = pickle.load(f)\n",
    "tknn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tuned_forest.sav', 'rb') as f:\n",
    "    tforest = pickle.load(f)\n",
    "tforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tuned_gboost.sav', 'rb') as f:\n",
    "    tgboost = pickle.load(f)\n",
    "tgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tuned_ada.sav', 'rb') as f:\n",
    "    tada = pickle.load(f)\n",
    "tada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tuned_xgb.sav', 'rb') as f:\n",
    "    txboost = pickle.load(f)\n",
    "txboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tuned_etc.sav', 'rb') as f:\n",
    "    tetc = pickle.load(f)\n",
    "tetc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('stack_1.sav', 'rb') as f:\n",
    "    stack_1 = pickle.load(f)\n",
    "stack_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('stack_1.sav', 'rb') as f:\n",
    "    stack_1 = pickle.load(f)\n",
    "stack_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('stack_2.sav', 'rb') as f:\n",
    "    stack_2 = pickle.load(f)\n",
    "stack_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('stack_3.sav', 'rb') as f:\n",
    "    stack_3 = pickle.load(f)\n",
    "stack_3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
